{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras_MNIST_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-TopicosEspeciaisEmBancoDeDados/blob/master/deeplearning/Keras_MNIST_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFDfn6xucIPz"
      },
      "source": [
        "## Keras - Reconhecimento de Dígitos (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOWs0me_cIP0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhpUWYJwcIP8"
      },
      "source": [
        "## Carregando arquivo de dígitos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB9stpCWcIP9"
      },
      "source": [
        "nb_classes = 10\n",
        "\n",
        "# the data, shuffled and split between tran and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(\"X_train original shape\", X_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVv7M8TfcIQA"
      },
      "source": [
        "Let's look at some examples of the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1vFd-PxcIQB"
      },
      "source": [
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVuPjfyUcIQE"
      },
      "source": [
        "## Formatar e  Colocar os dados em Escala \n",
        "Our neural-network is going to take a single vector for each training example, so we need to reshape the input so that each 28x28 image becomes a single 784 dimensional vector. We'll also scale the inputs to be in the range [0-1] rather than [0-255]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Q9REmIcIQF"
      },
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm0DR8vwcIQJ"
      },
      "source": [
        "Modify the target matrices to be in the one-hot format, i.e.\n",
        "\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "etc.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEfGsZGNcIQK"
      },
      "source": [
        "# codificação ONE-HOT ENCODING\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5dP0oIocIQN"
      },
      "source": [
        "Y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8FKld2wcIQR"
      },
      "source": [
        "# Construindo a Rede Neural\n",
        "Build the neural-network. Here we'll do a simple 3 layer fully connected network.\n",
        "<img src=\"https://raw.githubusercontent.com/vladimiralencar/Alunos-UEPB-TopicosEspeciaisEmBancoDeDados/master/deeplearning/data/figure.png\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45U_h6vQcIQS"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
        "                              # of the layer above. Here, with a \"rectified linear unit\",\n",
        "                              # we clamp all values below 0 to 0.\n",
        "                           \n",
        "model.add(Dropout(0.3))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
        "                                 # ensures the output is a valid probaility distribution, that is\n",
        "                                 # that its values are all non-negative and sum to 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bprkmGQxcIQW"
      },
      "source": [
        "## Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlNffN5XcIQX"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V_N8Ft-cIQb"
      },
      "source": [
        "## Train the model!\n",
        "This is the fun part: you can feed the training data loaded in earlier into this model and it will learn to classify digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7uvIivNcIQc"
      },
      "source": [
        "%%time\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=256, epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN4I2tmAcIQg"
      },
      "source": [
        "## Finally, evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESUE8YzEcIQh"
      },
      "source": [
        "loss = model.evaluate(X_test, Y_test,verbose=0)\n",
        "print('Acurácia de teste:', 1 - loss)\n",
        "\n",
        "_, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJ5z8Sg4qu_"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T6ozRm84qu_"
      },
      "source": [
        "![image](https://lh4.googleusercontent.com/ojMXAE77tiVVF3RSqK1lldysJx5OzBJdE5ng_0w7GpHYWl9GR9jjBN0p56UFW3dM3gEdS-0oTOw0IjORJXVImFvcXdD-EnFibJl06gxMN_kYTeOyfmanNEvXK59CYzt2t_3DifPG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA6O3OOJ4qu_"
      },
      "source": [
        "# define cnn model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) #kernel_initializer='he_uniform', \n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu')) #, kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "#opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR5PfERn4qu_"
      },
      "source": [
        "# reshape dataset to have a single channel\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)\n",
        "\n",
        "# one hot encode target values\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2jVaQtJ4qu_"
      },
      "source": [
        "%%time\n",
        "history = model.fit(X_train, Y_train, \n",
        "                    epochs=10, \n",
        "                    batch_size=512, #1024, #32, \n",
        "                    validation_data=(X_test, Y_test), \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS5XXNHg4qu_"
      },
      "source": [
        "_, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECkrQFAGcIQk"
      },
      "source": [
        "## Plotando algumas predições erradas do conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfQYcaQxcIQl"
      },
      "source": [
        "# classificações incorretas\n",
        "y_test_pred = model.predict_classes(X_test)\n",
        "#y_test_pred = np_utils.to_categorical(y_test_pred, nb_classes)\n",
        "\n",
        "miscl_img = X_test[y_test != y_test_pred][:25]\n",
        "correct_lab = y_test[y_test != y_test_pred][:25]\n",
        "miscl_lab = y_test_pred[y_test != y_test_pred][:25]\n",
        "\n",
        "\n",
        "#miscl_img = X_test[correct_indices]\n",
        "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
        "ax = ax.flatten()\n",
        "for i in range(10):\n",
        "    img = miscl_img[i].reshape(28, 28)\n",
        "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
        "    ax[i].set_title('%d) t: %d p: %d' % (i+1, correct_lab[i], miscl_lab[i]))\n",
        "\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IfepFdZcIQp"
      },
      "source": [
        "# Plotando algumas predições Corretas do conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9deHG7zKcIQq"
      },
      "source": [
        "# classificações corretas\n",
        "miscl_img = X_test[y_test == y_test_pred][:25]\n",
        "correct_lab = y_test[y_test == y_test_pred][:25]\n",
        "miscl_lab = y_test_pred[y_test == y_test_pred][:25]\n",
        "\n",
        "\n",
        "#miscl_img = X_test[correct_indices]\n",
        "fig, ax = plt.subplots(nrows=3, ncols=5, sharex=True, sharey=True,)\n",
        "ax = ax.flatten()\n",
        "for i in range(15):\n",
        "    img = miscl_img[i].reshape(28, 28)\n",
        "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
        "    ax[i].set_title('%d) t: %d p: %d' % (i+1, correct_lab[i], miscl_lab[i]))\n",
        "\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}